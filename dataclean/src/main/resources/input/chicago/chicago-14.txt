Leggetter, C. J. and Philip C. Woodland. “Maximum likelihood linear regression for speaker adaptation of continuous density hidden Markov models.” Computer Speech & Language 9 (1995): 171-185.

Joachims, Thorsten. “Training linear SVMs in linear time.” KDD (2006).

Mateos, Gonzalo, Juan Andrés Bazerque and Georgios B. Giannakis. “Distributed sparse linear regression.” IEEE Transactions on Signal Processing 58 (2010): 5262-5276.

Naseem, Imran, Roberto Togneri and Mohammed Bennamoun. “Linear Regression for Face Recognition.” IEEE Trans. Pattern Anal. Mach. Intell. 32 (2010): 2106-2112.

Breiman, Leo. “Bagging Predictors.” Machine Learning 24 (1996): 123-140.

Smola, Alexander J. and Bernhard Schölkopf. “A tutorial on support vector regression.” Statistics and Computing 14 (2004): 199-222.

Cristianini, Nello and John Shawe-Taylor. “An Introduction to Support Vector Machines and Other Kernel-based Learning Methods.” DAGLIB (2001).

Yang, Jianchao, Kai Yu, Yihong Gong and Thomas S. Huang. “Linear spatial pyramid matching using sparse coding for image classification.” CVPR (2009).

Larsson, Erik G. and Yngve Selén. “Linear Regression with a Sparse Parameter Vector.” ICASSP (2006).

Han, Jiawei and Micheline Kamber. “Data Mining: Concepts and Techniques.” MK (2000).

Leggetter, C. J. and Philip C. Woodland. “Maximum likelihood linear regression for speaker adaptation of continuous density hidden Markov models.” Computer Speech & Language 9 (1995): 171-185.

Joachims, Thorsten. “Training linear SVMs in linear time.” KDD (2006).

Mateos, Gonzalo, Juan Andrés Bazerque and Georgios B. Giannakis. “Distributed sparse linear regression.” IEEE Transactions on Signal Processing 58 (2010): 5262-5276.

Naseem, Imran, Roberto Togneri and Mohammed Bennamoun. “Linear Regression for Face Recognition.” IEEE Trans. Pattern Anal. Mach. Intell. 32 (2010): 2106-2112.

Breiman, Leo. “Bagging Predictors.” Machine Learning 24 (1996): 123-140.

Smola, Alexander J. and Bernhard Schölkopf. “A tutorial on support vector regression.” Statistics and Computing 14 (2004): 199-222.

Cristianini, Nello and John Shawe-Taylor. “An Introduction to Support Vector Machines and Other Kernel-based Learning Methods.” DAGLIB (2001).

Yang, Jianchao, Kai Yu, Yihong Gong and Thomas S. Huang. “Linear spatial pyramid matching using sparse coding for image classification.” CVPR (2009).

Larsson, Erik G. and Yngve Selén. “Linear Regression with a Sparse Parameter Vector.” ICASSP (2006).

Han, Jiawei and Micheline Kamber. “Data Mining: Concepts and Techniques.” MK (2000).

Das, Abhimanyu and David Kempe. “Algorithms for subset selection in linear regression.” STOC (2008).

Nair, Vinod and Geoffrey E. Hinton. “Rectified Linear Units Improve Restricted Boltzmann Machines.” ICML (2010).

Bishop, Christopher M. and Nasser M. Nasrabadi. “Pattern Recognition and Machine Learning.” J. Electronic Imaging 16 (2007): 049901.

Saunders, Craig, Alexander Gammerman and Volodya Vovk. “Ridge Regression Learning Algorithm in Dual Variables.” ICML (1998).

Cao, Xudong, Yichen Wei, Fang Wen and Jian Sun. “Face alignment by Explicit Shape Regression.” CVPR (2012).

Takeda, Hiroyuki, Sina Farsiu and Peyman Milanfar. “Kernel Regression for Image Processing and Reconstruction.” IEEE Transactions on Image Processing 16 (2007): 349-366.

Du, Wenliang, Yunghsiang S. Han and Shigang Chen. “Privacy-Preserving Multivariate Statistical Analysis: Linear Regression and Classification.” SDM (2004).

Walsh, Thomas J., Istvan Szita, Carlos Diuk and Michael L. Littman. “Exploring compact reinforcement-learning representations with linear regression.” UAI (2009).

Dobra, Alin and Johannes Gehrke. “SECRET: a scalable linear regression tree algorithm.” KDD (2002).

Chen, Kuan-Ting, Wen-Wei Liau, Hsin-Min Wang and Lin-Shan Lee. “Fast speaker adaptation using eigenspace-based maximum likelihood linear regression.” INTERSPEECH (2000).

Wright, John, Allen Y. Yang, Arvind Ganesh, Shankar S. Sastry and Yi Ma. “Robust Face Recognition via Sparse Representation.” IEEE Trans. Pattern Anal. Mach. Intell. 31 (2009): 210-227.

Chang, Chih-Chung and Chih-Jen Lin. “LIBSVM: A library for support vector machines.” ACM TIST 2 (2011): 27.

Joseph, P. J., Kapil Vaswani and Matthew J. Thazhuthaveetil. “Construction and use of linear regression models for processor performance analysis.” HPCA (2006).

Karalic, Aram. “Employing Linear Regression in Regression Tree Leaves.” ECAI (1992).

Vovk, Volodya. “Competitive On-line Linear Regression.” NIPS (1997).

Drucker, Harris, Christopher J. C. Burges, Linda Kaufman, Alexander J. Smola and Vladimir Vapnik. “Support Vector Regression Machines.” NIPS (1996).

Meng, Xiangrui and Michael W. Mahoney. “Low-distortion subspace embeddings in input-sparsity time and applications to robust linear regression.” STOC (2013).

Nguyen, Dong, Noah A. Smith and Carolyn Penstein Rosé. “Author Age Prediction from Text using Linear Regression.”  (2011).

Strehl, Alexander L. and Michael L. Littman. “Online Linear Regression and Its Application to Model-Based Reinforcement Learning.” NIPS (2007).

Witten, Ian H. and Eibe Frank. “Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.” MK (1999).

Siohan, Olivier, Tor André Myrvoll and Chin-Hui Lee. “Structural maximum a posteriori linear regression for fast HMM adaptation.” Computer Speech & Language 16 (2002): 5-24.

Bazrafshan, Marzieh, Tagyoung Chung and Daniel Gildea. “Tuning as Linear Regression.” NAACL (2012).

Recht, Benjamin, Maryam Fazel and Pablo A. Parrilo. “Guaranteed Minimum-Rank Solutions of Linear Matrix Equations via Nuclear Norm Minimization.” SIAM Review 52 (2010): 471-501.

Jin, Yuzhe and Bhaskar D. Rao. “Algorithms for robust linear regression by exploiting the connection to sparse signal recovery.” ICASSP (2010).

Landwehr, Niels, Mark A. Hall and Eibe Frank. “Logistic Model Trees.” ECML (2003).

Raskutti, Garvesh, Martin J. Wainwright and Bin Yu. “Minimax rates of estimation for high-dimensional linear regression over $\ell_q$-balls.”  (2009).

Dantone, Matthias, Juergen Gall, Gabriele Fanelli and Luc J. Van Gool. “Real-time facial feature detection using conditional regression forests.” CVPR (2012).

Mangasarian, Olvi L. and David R. Musicant. “Robust Linear and Support Vector Regression.” IEEE Trans. Pattern Anal. Mach. Intell. 22 (2000): 950-955.

Vijayakumar, Sethu and Stefan Schaal. “Locally Weighted Projection Regression : an O(n) Algorithm for Incremental Real Time Learning in High Dimensional Space.”  (2001).

Candela, Joaquin Quiñonero and Carl Edward Rasmussen. “A Unifying View of Sparse Approximate Gaussian Process Regression.” Journal of Machine Learning Research 6 (2005): 1939-1959.

Goel, Nagendra, Jan Silovsk´y, Daniel Povey, Arnab Ghoshal, Petr Motlíček, Yanmin Qian, Gilles Boulianne, Mirko Hannemann, Georg Stemmer, Petr Schwarz, Ondřej Glembek, Karel Vesel´y and Lukáš Burget. “The Kaldi Speech Recognition Toolkit.”  (2013).

Tappen, Marshall F., Edward H. Adelson and William T. Freeman. “Estimating Intrinsic Component Images using Non-Linear Regression.” CVPR (2006).

Guestrin, Carlos, Peter Bodík, Romain Thibaux, Mark A. Paskin and Samuel Madden. “Distributed regression: an efficient framework for modeling sensor network data.” IPSN (2004).

Meyer, Gilles, Silvere Bonnabel and Rodolphe Sepulchre. “Linear Regression under Fixed-Rank Constraints: A Riemannian Approach.” ICML (2011).

Dollár, Piotr, Peter Welinder and Pietro Perona. “Cascaded pose regression.” CVPR (2010).

Bastien, Philippe, Vincenzo Esposito Vinzi and Michel Tenenhaus. “PLS generalised linear regression.” Computational Statistics & Data Analysis 48 (2005): 17-46.

Neumann, László, Balázs Csébfalvi, Andreas König and Eduard Gröller. “Gradient Estimation in Volume Data using 4D Linear Regression.” Comput. Graph. Forum 19 (2000): 351-358.

Papineni, Kishore, Salim Roukos, Todd Ward and Wei-Jing Zhu. “Bleu: a Method for Automatic Evaluation of Machine Translation.” ACL (2002).

Vogel, David S., Ognian Asparouhov and Tobias Scheffer. “Scalable look-ahead linear regression trees.” KDD (2007).

Huang, Xiaohong and Wei Pan. “Linear regression and two-class classification with gene expression data.” Bioinformatics 19 (2003): 2072-2078.

Chu, Wei and Zoubin Ghahramani. “Gaussian Processes for Ordinal Regression.” Journal of Machine Learning Research 6 (2005): 1019-1041.

Rahimi, Ali and Benjamin Recht. “Random Features for Large-Scale Kernel Machines.” NIPS (2007).

Lin, Chih-Jen, Ruby C. Weng and S. Sathiya Keerthi. “Trust region Newton methods for large-scale logistic regression.” ICML (2007).

Agarwal, Ankur and Bill Triggs. “3D Human Pose from Silhouettes by Relevance Vector Regression.” CVPR (2004).

Chu, Cheng-Tao, Sang Kyun Kim, Yi-An Lin, YuanYuan Yu, Gary R. Bradski, Andrew Y. Ng and Kunle Olukotun. “Map-Reduce for Machine Learning on Multicore.” NIPS (2006).

Kim, Jingu and Haesun Park. “Fast Active-set-type Algorithms for L1-regularized Linear Regression.” JMLR (2010).

Hazan, Elad and Tomer Koren. “Linear Regression with Limited Observation.” ICML (2012).

Hall, Mark A., Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann and Ian H. Witten. “The WEKA data mining software: an update.” SIGKDD Explorations 11 (2009): 10-18.

Gunawardana, Asela and William Byrne. “Discriminative speaker adaptation with conditional maximum likelihood linear regression.” INTERSPEECH (2001).

Lu, Feng, Yusuke Sugano, Takahiro Okabe and Yoichi Sato. “Inferring human gaze from appearance via adaptive linear regression.” ICCV (2011).

Lu, Zhaosong, Renato D. C. Monteiro and Ming Yuan. “Convex optimization methods for dimension reduction and coefficient estimation in multivariate linear regression.” Math. Program. 131 (2012): 163-194.

Blei, David M. and Jon D. McAuliffe. “Supervised Topic Models.” NIPS (2007).

Ferrari-Trecate, Giancarlo and Marco Muselli. “A New Learning Method for Piecewise Linear Regression.” ICANN (2002).

Xiong, Xuehan and Fernando De la Torre. “Supervised Descent Method and Its Applications to Face Alignment.” CVPR (2013).

Hatzivassiloglou, Vasileios and Kathleen McKeown. “Predicting the Semantic Orientation of Adjectives.” ACL (1997).

Koh, Kwangmoo, Seung-Jean Kim, Stephen Boyd and Yi Lin. “An Interior-point Method for Large-scale 1 -regularized Logistic Regression.”  (2007).

Gaffney, Scott and Padhraic Smyth. “Trajectory Clustering with Mixtures of Regression Models.” KDD (1999).

Cristinacce, David and Timothy F. Cootes. “Boosted Regression Active Shape Models.” BMVC (2007).

Gales, M. J. F.. “Maximum likelihood linear transformations for HMM-based speech recognition.” Computer Speech & Language 12 (1998): 75-98.

He, Xiaodong and Wu Chou. “Minimum classification error linear regression for acoustic model adaptation of continuous density HMMs.” ICASSP (2003).

Ren, Shaoqing, Xudong Cao, Yichen Wei and Jian Sun. “Face Alignment at 3000 FPS via Regressing Local Binary Features.” CVPR (2014).

Ye, Jieping. “Least squares linear discriminant analysis.” ICML (2007).

Tipping, Michael E.. “Sparse Bayesian Learning and the Relevance Vector Machine.” Journal of Machine Learning Research 1 (2001): 211-244.

Cai, Deng, Xiaofei He and Jiawei Han. “Spectral Regression for Efficient Regularized Subspace Learning.” ICCV (2007).

Frénay, Benoît and Michel Verleysen. “Parameter-insensitive kernel in extreme learning for non-linear support vector regression.” Neurocomputing 74 (2011): 2526-2531.

Agarwal, Ankur and Bill Triggs. “Recovering 3D Human Pose from Monocular Images.” IEEE Trans. Pattern Anal. Mach. Intell. 28 (2006): 44-58.

Rosipal, Roman and Leonard J. Trejo. “Kernel Partial Least Squares Regression in Reproducing Kernel Hilbert Space.” Journal of Machine Learning Research 2 (2001): 97-123.

Dempster, A P., N M. Laird, D B. Rubin and D B. Rdin. “Maximum Likelihood from Incomplete Data via the Em Algorithm Maximum Likelihood from Incomplete Data via the Em Algorithm.”  (2007).

Krishnapuram, Balaji, Lawrence Carin, Mário A. T. Figueiredo and Alexander J. Hartemink. “Sparse Multinomial Logistic Regression: Fast Algorithms and Generalization Bounds.” IEEE Trans. Pattern Anal. Mach. Intell. 27 (2005): 957-968.

Mimno, David M. and Andrew McCallum. “Topic Models Conditioned on Arbitrary Features with Dirichlet-multinomial Regression.” UAI (2008).

Zhou, Xiaobo, Xiaodong Wang and Edward R. Dougherty. “Missing-value estimation using linear and non-linear regression with Bayesian gene selection.” Bioinformatics 19 (2003): 2302-2307.

Clarkson, Kenneth L., Petros Drineas, Malik Magdon-Ismail, Michael W. Mahoney, Xiangrui Meng and David P. Woodruff. “The Fast Cauchy Transform and Faster Robust Linear Regression.” SODA (2013).

Ho, Chia-Hua and Chih-Jen Lin. “Large-scale linear support vector regression.” Journal of Machine Learning Research 13 (2012): 3323-3348.

Carreira, João and Cristian Sminchisescu. “Constrained parametric min-cuts for automatic object segmentation.” CVPR (2010).

Chaganty, Arun Tejasvi and Percy Liang. “Spectral Experts for Estimating Mixtures of Linear Regressions.” ICML (2013).

Vijayakumar, Sethu, Aaron DSouza and Stefan Schaal. “Incremental Online Learning in High Dimensions.” Neural Computation 17 (2005): 2602-2634.

Chotimongkol, Ananlada and Alexander I. Rudnicky. “N-best speech hypotheses reordering using linear regression.” INTERSPEECH (2001).

Rothermel, Gregg and Mary Jean Harrold. “A Safe, Efficient Regression Test Selection Technique.” ACM Trans. Softw. Eng. Methodol. 6 (1997): 173-210.

Torgo, Luís and Joaquim Pinto da Costa. “Clustered Partial Linear Regression.” ECML (2000).

Breiman, Leo. “Stacked Regressions.” Machine Learning 24 (1996): 49-64.

Sarwar, Badrul M., George Karypis, Joseph A. Konstan and John Riedl. “Item-based collaborative filtering recommendation algorithms.” WWW (2001).

Yang, Eunho, Aurelie C. Lozano and Pradeep D. Ravikumar. “Elementary Estimators for High-Dimensional Linear Regression.” ICML (2014).

Maillard, Odalric-Ambrym and Rémi Munos. “Compressed Least-Squares Regression.” NIPS (2009).

Cherkassky, Vladimir and Yunqian Ma. “Practical selection of SVM parameters and noise estimation for SVM regression.” Neural Networks 17 (2004): 113-126.

Öztireli, A. Cengiz, Gaël Guennebaud and Markus H. Gross. “Feature Preserving Point Set Surfaces based on Non-Linear Kernel Regression.” Comput. Graph. Forum 28 (2009): 493-501.

Goetschalckx, Robby, Kurt Driessens and Scott Sanner. “Cost-Sensitive Parsimonious Linear Regression.” ICDM (2008).

Whitehouse, Kamin and David E. Culler. “Calibration as parameter estimation in sensor networks.” MOBICOM (2002).

Clarkson, Kenneth L. and David P. Woodruff. “Numerical linear algebra in the streaming model.” STOC (2009).

Sugiyama, Masashi. “Active Learning in Approximately Linear Regression Based on Conditional Expectation of Generalization Error.” Journal of Machine Learning Research 7 (2006): 141-166.

Ray, Soumya and David Page. “Multiple Instance Regression.” ICML (2001).

Zhang, Jun, Zhenjie Zhang, Xiaokui Xiao, Yin Yang and Marianne Winslett. “Functional Mechanism: Regression Analysis under Differential Privacy.” CoRR abs/1208.0219 (2012): n. pag.

Guyon, Isabelle and André Elisseeff. “An Introduction to Variable and Feature Selection.” Journal of Machine Learning Research 3 (2003): 1157-1182.

Yi, Xinyang, Constantine Caramanis and Sujay Sanghavi. “Alternating Minimization for Mixed Linear Regression.” ICML (2014).

Chaudhuri, Kamalika and Claire Monteleoni. “Privacy-preserving logistic regression.” NIPS (2008).

Tropp, Joel A.. “Just relax: convex programming methods for identifying sparse signals in noise.” IEEE Transactions on Information Theory 52 (2006): 1030-1051.

Mangasarian, Olvi L. and David R. Musicant. “Large Scale Kernel Regression via Linear Programming.” Machine Learning 46 (2002): 255-269.

Chien, Jen-Tzung. “Quasi-Bayes linear regression for sequential learning of hidden Markov models.” IEEE Transactions on Speech and Audio Processing 10 (2002): 268-278.

Grefenstette, Edward, Georgiana Dinu, Yao-Zhong Zhang, Mehrnoosh Sadrzadeh and Marco Baroni. “Multi-Step Regression Learning for Compositional Distributional Semantics.” CoRR abs/1301.6939 (2013): n. pag.

Vapnik, Vladimir, Steven E. Golowich and Alexander J. Smola. “Support Vector Method for Function Approximation, Regression Estimation and Signal Processing.” NIPS (1996).

Chu, Wei and S. Sathiya Keerthi. “New approaches to support vector ordinal regression.” ICML (2005).

Collobert, Ronan and Samy Bengio. “SVMTorch: Support Vector Machines for Large-Scale Regression Problems.” Journal of Machine Learning Research 1 (2001): 143-160.

Schmidt, Daniel Francis and Enes Makalic. “MML Invariant Linear Regression.” AUSAI (2009).

Williams, Christopher K. I. and Carl Edward Rasmussen. “Gaussian Processes for Regression.” NIPS (1995).

Oliva, Aude and Antonio Torralba. “Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope.” International Journal of Computer Vision 42 (2001): 145-175.

Rockafellar, R. Tyrrell, Stan Uryasev and Michael Zabarankin. “Risk Tuning with Generalized Linear Regression.” Math. Oper. Res. 33 (2008): 712-729.

Tropp, Joel A. and Stephen J. Wright. “Computational Methods for Sparse Solution of Linear Inverse Problems.” Proceedings of the IEEE 98 (2010): 948-958.

Kaban, Ata. “New Bounds on Compressive Linear Least Squares Regression.” AISTATS (2014).

Collins, Michael, Robert E. Schapire and Yoram Singer. “Logistic Regression, AdaBoost and Bregman Distances.” COLT (2000).

Sarlós, Tamás. “Improved Approximation Algorithms for Large Matrices via Random Projections.” FOCS (2006).

Lee, Benjamin C. and David M. Brooks. “Accurate and efficient regression modeling for microarchitectural performance and power prediction.” ASPLOS (2006).

Hannah, Lauren, David M. Blei and Warren B. Powell. “Dirichlet Process Mixtures of Generalized Linear Models.” JMLR (2010).

Ferraro, Maria Brigida, Renato Coppi, G. González Rodríguez and Ana Colubi. “A linear regression model for imprecise response.” Int. J. Approx. Reasoning 51 (2010): 759-770.

Plan, Yaniv and Roman Vershynin. “Robust 1-bit compressed sensing and sparse logistic regression: A convex programming approach.” CoRR abs/1202.1212 (2013): n. pag.

Li, Chaoqun and Hongwei Li. “An Improved Instance Weighted Linear Regression.” JCIT 5 (2010): 122-128.

Xu, Xin and Eibe Frank. “Logistic Regression and Boosting for Labeled Bags of Instances.” PAKDD (2004).

Kersting, Kristian, Christian Plagemann, Patrick Pfaff and Wolfram Burgard. “Most likely heteroscedastic Gaussian process regression.” ICML (2007).

Gerchinovitz, Sébastien. “Sparsity Regret Bounds for Individual Sequences in Online Linear Regression.” JMLR (2011).

Liu, Xianming, Debin Zhao, Ruiqin Xiong, Siwei Ma and Wen Gao. “Image interpolation via regularized local linear regression.” PCS (2010).

Jaakkola, Tommi S. and David Haussler. “Probabilistic kernel regression models.” AISTATS (1999).

Kim, Seyoung and Eric P. Xing. “Tree-Guided Group Lasso for Multi-Task Regression with Structured Sparsity.” ICML (2010).

Salimans, Tim and David A. Knowles. “Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression.” CoRR abs/1206.6679 (2012): n. pag.

Hsieh, Cho-Jui, Kai-Wei Chang, Chih-Jen Lin, S. Sathiya Keerthi and S. Sundararajan. “A dual coordinate descent method for large-scale linear SVM.” ICML (2008).

Boutsidis, Christos, Petros Drineas and Malik Magdon-Ismail. “Sparse Features for PCA-Like Linear Regression.” NIPS (2011).

Zhou, Shaohua Kevin and Dorin Comaniciu. “Shape Regression Machine.” IPMI (2007).

Cootes, Timothy F., Mircea C. Ionita, Claudia Lindner and Patrick Sauer. “Robust and Accurate Shape Model Fitting Using Random Forest Regression Voting.” ECCV (2012).

DUrso, Pierpaolo and Adriana Santoro. “Fuzzy clusterwise linear regression analysis with symmetrical fuzzy output variable.” Computational Statistics & Data Analysis 51 (2006): 287-313.

Wiesel, Ami, Yonina C. Eldar and Arie Yeredor. “Linear Regression With Gaussian Model Uncertainty: Algorithms and Bounds.” IEEE Transactions on Signal Processing 56 (2008): 2194-2205.

Lawrence, Neil D. and Raquel Urtasun. “Non-linear matrix factorization with Gaussian processes.” ICML (2009).

DUrso, Pierpaolo. “Linear regression analysis for fuzzy/crisp input and fuzzy/crisp output data.” Computational Statistics & Data Analysis 42 (2003): 47-72.

Atkeson, Christopher G., Andrew W. Moore and Stefan Schaal. “Locally Weighted Learning.” Artif. Intell. Rev. 11 (1997): 11-73.

Davis, Bradley C., P. Thomas Fletcher, Elizabeth Bullitt and Sarang C. Joshi. “Population Shape Regression From Random Design Data.” ICCV (2007).

Shannon, William D., Maciej Faifer, Michael A. Province and D. C. Rao. “Tree-Based Models for Fiting Stratified Linear Regression Models.” J. Classification 19 (2002): 113-130.

Elbaum, Sebastian G., Alexey G. Malishevsky and Gregg Rothermel. “Prioritizing test cases for regression testing.” ISSTA (2000).

Chu, Wei and S. Sathiya Keerthi. “Support Vector Ordinal Regression.” Neural Computation 19 (2007): 792-815.

Gupta, Maya R., Eric K. Garcia and E. Chin. “Adaptive Local Linear Regression With Application to Printer Color Management.” IEEE Transactions on Image Processing 17 (2008): 936-945.

Asur, Sitaram and Bernardo A. Huberman. “Predicting the Future with Social Media.” WEBI (2010).

Maróti, Miklós, Branislav Kusy, Gyula Simon and Ákos Lédeczi. “The flooding time synchronization protocol.” SENSYS (2004).

Yang, Miin-Shen and Hsien-Hsiung Liu. “Fuzzy least-squares algorithms for interactive fuzzy linear regression models.” Fuzzy Sets and Systems 135 (2003): 305-316.

Li, Zheng, Mark Harman and Robert M. Hierons. “Search Algorithms for Regression Test Case Prioritization.” IEEE Trans. Software Eng. 33 (2007): 225-237.

Ari, Bertan and H. Altay Güvenir. “Clustered linear regression.” Knowl.-Based Syst. 15 (2002): 169-175.

Yamada, Makoto and Masashi Sugiyama. “Dependence Minimizing Regression with Model Selection for Non-Linear Causal Inference under Non-Gaussian Noise.” AAAI (2010).

Zhu, Jun, Amr Ahmed and Eric P. Xing. “MedLDA: maximum margin supervised topic models for regression and classification.” ICML (2009).

Chai, Xiujuan, Shiguang Shan, Xilin Chen and Wen Gao. “Local Linear Regression (LLR) for Pose Invariant Face Recognition.” FGR (2006).

Bourdev, Lubomir D. and Jitendra Malik. “Poselets: Body part detectors trained using 3D human pose annotations.” ICCV (2009).

Lee, Wee Sun and Bing Liu. “Learning with Positive and Unlabeled Examples Using Weighted Logistic Regression.” ICML (2003).

Pang, Bo and Lillian Lee. “Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales.” ACL (2005).

Guo, Guodong, Yun Fu, Charles R. Dyer and Thomas S. Huang. “Image-Based Human Age Estimation by Manifold Learning and Locally Adjusted Robust Regression.” IEEE Transactions on Image Processing 17 (2008): 1178-1188.

Chan, Antoni B. and Nuno Vasconcelos. “Bayesian Poisson regression for crowd counting.” ICCV (2009).

Kivinen, Jyrki and Manfred K. Warmuth. “Relative Loss Bounds for Multidimensional Regression Problems.” NIPS (1997).

Demiriz, Ayhan, Kristin P. Bennett and John Shawe-Taylor. “Linear Programming Boosting via Column Generation.” Machine Learning 46 (2002): 225-254.

Valstar, Michel François, Brais Martínez, Xavier Binefa and Maja Pantic. “Facial point detection using boosted regression and graph models.” CVPR (2010).

Simonyan, Karen and Andrew Zisserman. “Very Deep Convolutional Networks for Large-Scale Image Recognition.” CoRR abs/1409.1556 (2014): n. pag.

Li, Li-Jia, Hao Su, Eric P. Xing and Li Fei-Fei. “Object Bank: A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification.” NIPS (2010).

Xue, Gengjian, Li Song, Jun Sun and Meng Wu. “Foreground estimation based on robust linear regression model.” ICIP (2011).

Weinberger, Kilian Q. and Gerald Tesauro. “Metric Learning for Kernel Regression.” JMLR (2007).

Zhao, Bing, Klaus Zechner, Stephan Vogel and Alex Waibel. “Efficient Optimization For Bilingual Sentence Alignment Based On Linear Regression.”  (2003).

Mikolov, Tomas, Ilya Sutskever, Kai Chen, Gregory S. Corrado and Jeffrey Dean. “Distributed Representations of Words and Phrases and their Compositionality.” NIPS (2013).

Sauer, Patrick, Timothy F. Cootes and Christopher J. Taylor. “Accurate Regression Procedures for Active Appearance Models.” BMVC (2011).

Cortes, Corinna, Mehryar Mohri and Afshin Rostamizadeh. “Learning Non-Linear Combinations of Kernels.” NIPS (2009).

Torgo, Luís. “Functional Models for Regression Tree Leaves.” ICML (1997).

Zeng, Hua-Jun, Qi-Cai He, Zheng Chen, Wei-Ying Ma and Jinwen Ma. “Learning to cluster web search results.” SIGIR (2004).

Zhao, Qibin, Cesar F. Caiafa, Danilo P. Mandic, Zenas C. Chao, Yasuo Nagasaka, Naotaka Fujii, Liqing Zhang and Andrzej Cichocki. “Higher-Order Partial Least Squares (HOPLS): A Generalized Multi-Linear Regression Method.” CoRR abs/1207.1230 (2013): n. pag.

Criminisi, Antonio, Jamie Shotton, Duncan P. Robertson and Ender Konukoglu. “Regression Forests for Efficient Anatomy Detection and Localization in CT Studies.” MICCAI (2010).

Rwebangira, Mugizi Robert and John Lafferty. “Local Linear Semi-supervised Regression.”  (2009).

Sugiyama, Masashi and Shinichi Nakajima. “Pool-based active learning in approximate linear regression.” Machine Learning 75 (2009): 249-274.

Dredze, Mark, Koby Crammer and Fernando Pereira. “Confidence-weighted linear classification.” ICML (2008).

Merz, Christopher J. and Michael J. Pazzani. “Combining Neural Network Regression Estimates with Regularized Linear Weights.” NIPS (1996).

Schein, Andrew I. and Lyle H. Ungar. “Active learning for logistic regression: an evaluation.” Machine Learning 68 (2007): 235-265.

Chen, Xi, Qihang Lin, Seyoung Kim, Jaime G. Carbonell and Eric P. Xing. “Smoothing proximal gradient method for general structured sparse regression.”  (2010).

Carvalho, Carlos Giovanni Nunes de, Danielo Goncalves Gomes, José Neuman de Souza and Nazim Agoulmine. “Multiple linear regression to improve prediction accuracy in WSN data reduction.” LANOMS (2011).

Ristanoski, Goce, Wei Liu and James Bailey. “Time Series Forecasting Using Distribution Enhanced Linear Regression.” PAKDD (2013).

Chan, Antoni B. and Nuno Vasconcelos. “Counting People With Low-Level Features and Bayesian Regression.” IEEE Transactions on Image Processing 21 (2012): 2160-2177.

Lai, Jian and Xudong Jiang. “Robust face recognition using trimmed linear regression.” ICASSP (2013).

Seeger, Matthias W., Christopher K. I. Williams and Neil D. Lawrence. “Fast Forward Selection to Speed Up Sparse Gaussian Process Regression.” AISTATS (2003).

Girshick, Ross B., Jamie Shotton, Pushmeet Kohli, Antonio Criminisi and Andrew W. Fitzgibbon. “Efficient regression of general-activity human poses from depth images.” ICCV (2011).

Graves, Todd L., Mary Jean Harrold, Jung-Min Kim, Adam A. Porter and Gregg Rothermel. “An Empirical Study of Regression Test Selection Techniques.” ICSE (1998).

Sculley, D.. “Combined regression and ranking.” KDD (2010).

Gu, Allan and Avideh Zakhor. “Optical Proximity Correction with Linear Regression.”  (2007).

Tropp, Joel A. and Anna C. Gilbert. “Signal Recovery From Random Measurements Via Orthogonal Matching Pursuit.” IEEE Transactions on Information Theory 53 (2007): 4655-4666.

Wang, Weiguang, Yingbin Liang and Eric P. Xing. “Block Regularized Lasso for Multivariate Multi-Response Linear Regression.” AISTATS (2013).

